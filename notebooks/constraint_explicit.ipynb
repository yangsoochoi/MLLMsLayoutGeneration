{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"rico\", \"publaynet\"]  # choices\n",
    "tasks = [\"gent\", \"gents\", \"genr\", \"completion\", \"refinement\"]\n",
    "dataset = datasets[0]\n",
    "task = tasks[0]\n",
    "input_format = \"seq\"\n",
    "output_format = \"html\"\n",
    "add_unk_token = False\n",
    "add_index_token = True\n",
    "add_sep_token = True\n",
    "candidate_size = -1  # -1 represents the complete training set\n",
    "num_prompt = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from preprocess import create_processor\n",
    "from utils import RAW_DATA_PATH, read_pt, write_pt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "processor = create_processor(dataset=dataset, task=task)\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "\n",
    "def get_processed_data(split):\n",
    "    filename = os.path.join(\n",
    "        base_dir, \"dataset\", dataset, \"processed\", task, f\"{split}.pt\"\n",
    "    )\n",
    "    if os.path.exists(filename):\n",
    "        processed_data = read_pt(filename)\n",
    "    else:\n",
    "        processed_data = []\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        raw_path = os.path.join(RAW_DATA_PATH(dataset), f\"{split}.pt\")\n",
    "        raw_data = read_pt(raw_path)\n",
    "        for rd in tqdm(raw_data, desc=f\"{split} data processing...\"):\n",
    "            processed_data.append(processor(rd))\n",
    "        write_pt(filename, processed_data)\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "processed_train_data = get_processed_data(\"train\")\n",
    "processed_val_data = get_processed_data(\"val\")\n",
    "processed_test_data = get_processed_data(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic exemplar selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection import create_selector\n",
    "\n",
    "selector = create_selector(\n",
    "    task=task,\n",
    "    train_data=processed_train_data,\n",
    "    candidate_size=candidate_size,\n",
    "    num_prompt=num_prompt,\n",
    ")\n",
    "\n",
    "test_idx = 0\n",
    "exemplars = selector(processed_test_data[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input-output serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serialization import create_serializer, build_prompt\n",
    "\n",
    "serializer = create_serializer(\n",
    "    dataset=dataset,\n",
    "    task=task,\n",
    "    input_format=input_format,\n",
    "    output_format=output_format,\n",
    "    add_index_token=add_index_token,\n",
    "    add_sep_token=add_sep_token,\n",
    "    add_unk_token=add_unk_token\n",
    ")\n",
    "prompt = build_prompt(serializer, exemplars, processed_test_data[test_idx], dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please generate a layout based on the given Image. The task that finds each element in the corresponding image and makes it into an HTML structure.You need to ensure that the generated layout looks realistic, with elements well aligned and avoiding unnecessary overlap.\n",
      "Task Description: generation conditioned on given element types\n",
      "Layout Domain: android layout\n",
      "Canvas Size: canvas width is 90px, canvas height is 160px\n",
      "\n",
      "Element Type Constraint: icon 0 | icon 1 | icon 2 | image 3 | image 4 | text 5 | text button 6 | text button 7 | video 8\n",
      "<html>\n",
      "<body>\n",
      "<div class=\"canvas\" style=\"left: 0px; top: 0px; width: 90px; height: 160px\"></div>\n",
      "<div class=\"icon\" style=\"index: 0; left: 2px; top: 8px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"icon\" style=\"index: 1; left: 74px; top: 118px; width: 12px; height: 12px\"></div>\n",
      "<div class=\"icon\" style=\"index: 2; left: 74px; top: 133px; width: 12px; height: 12px\"></div>\n",
      "<div class=\"image\" style=\"index: 3; left: 0px; top: 5px; width: 90px; height: 12px\"></div>\n",
      "<div class=\"image\" style=\"index: 4; left: 0px; top: 122px; width: 90px; height: 26px\"></div>\n",
      "<div class=\"text\" style=\"index: 5; left: 30px; top: 26px; width: 28px; height: 3px\"></div>\n",
      "<div class=\"text button\" style=\"index: 6; left: 0px; top: 38px; width: 90px; height: 36px\"></div>\n",
      "<div class=\"text button\" style=\"index: 7; left: 0px; top: 75px; width: 90px; height: 44px\"></div>\n",
      "<div class=\"video\" style=\"index: 8; left: 0px; top: 120px; width: 90px; height: 28px\"></div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Element Type Constraint: image 0 | image 1 | image 2 | image 3 | image 4 | image 5 | image 6 | image 7 | text 8 | text button 9 | text button 10 | text button 11\n",
      "<html>\n",
      "<body>\n",
      "<div class=\"canvas\" style=\"left: 0px; top: 0px; width: 90px; height: 160px\"></div>\n",
      "<div class=\"image\" style=\"index: 0; left: 0px; top: 0px; width: 56px; height: 109px\"></div>\n",
      "<div class=\"image\" style=\"index: 1; left: 0px; top: 0px; width: 90px; height: 109px\"></div>\n",
      "<div class=\"image\" style=\"index: 2; left: 0px; top: 0px; width: 90px; height: 89px\"></div>\n",
      "<div class=\"image\" style=\"index: 3; left: 31px; top: 102px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"image\" style=\"index: 4; left: 37px; top: 102px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"image\" style=\"index: 5; left: 42px; top: 102px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"image\" style=\"index: 6; left: 47px; top: 102px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"image\" style=\"index: 7; left: 52px; top: 102px; width: 5px; height: 5px\"></div>\n",
      "<div class=\"text\" style=\"index: 8; left: 5px; top: 89px; width: 79px; height: 8px\"></div>\n",
      "<div class=\"text button\" style=\"index: 9; left: 7px; top: 112px; width: 76px; height: 8px\"></div>\n",
      "<div class=\"text button\" style=\"index: 10; left: 7px; top: 125px; width: 76px; height: 8px\"></div>\n",
      "<div class=\"text button\" style=\"index: 11; left: 7px; top: 137px; width: 76px; height: 8px\"></div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "Element Type Constraint: image 0 | image 1 | image 2 | image 3 | pager indicator 4 | text 5 | text 6 | text button 7 | text button 8\n",
      "\n",
      "\n",
      "Do not add comments and any explanations. The return result must only include the html code\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo-instruct\"\n",
    "temperature = 0.7\n",
    "max_tokens = 800\n",
    "top_p = 1\n",
    "frequency_penalty = 0\n",
    "presence_penalty = 0\n",
    "num_return = 3\n",
    "stop_token = \"\\n\\n\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=model,\n",
    "    prompt=prompt,\n",
    "    temperature=temperature,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=top_p,\n",
    "    frequency_penalty=frequency_penalty,\n",
    "    presence_penalty=presence_penalty,\n",
    "    n=num_return,\n",
    "    stop=[stop_token],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter 0 invalid response\n"
     ]
    }
   ],
   "source": [
    "from parsing import Parser\n",
    "\n",
    "\n",
    "parser = Parser(dataset=dataset, output_format=output_format)\n",
    "parsed_response = parser(response)\n",
    "print(f\"filter {num_return - len(parsed_response)} invalid response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m val_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RAW_DATA_PATH(dataset), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m ranker \u001b[38;5;241m=\u001b[39m Ranker(val_path\u001b[38;5;241m=\u001b[39mval_path)\n\u001b[1;32m----> 5\u001b[0m ranked_response \u001b[38;5;241m=\u001b[39m \u001b[43mranker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\didtn\\layoutgeneration\\layoutgeneration\\layoutprompter\\src\\ranker.py:36\u001b[0m, in \u001b[0;36mRanker.__call__\u001b[1;34m(self, predictions)\u001b[0m\n\u001b[0;32m     34\u001b[0m metric \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m _pred_labels \u001b[38;5;241m=\u001b[39m pred_labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m _pred_bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_ltwh_to_ltrb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_bboxes\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m _pred_padding_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(_pred_labels)\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m     38\u001b[0m metric\u001b[38;5;241m.\u001b[39mappend(compute_alignment(_pred_bboxes, _pred_padding_mask))\n",
      "File \u001b[1;32mc:\\users\\didtn\\layoutgeneration\\layoutgeneration\\layoutprompter\\src\\utils.py:106\u001b[0m, in \u001b[0;36mconvert_ltwh_to_ltrb\u001b[1;34m(bbox)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_ltwh_to_ltrb\u001b[39m(bbox):\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bbox\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 106\u001b[0m         l, t, w, h \u001b[38;5;241m=\u001b[39m bbox\n\u001b[0;32m    107\u001b[0m         r \u001b[38;5;241m=\u001b[39m l \u001b[38;5;241m+\u001b[39m w\n\u001b[0;32m    108\u001b[0m         b \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m h\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 0)"
     ]
    }
   ],
   "source": [
    "from ranker import Ranker\n",
    "\n",
    "val_path = os.path.join(RAW_DATA_PATH(dataset), \"val.pt\")\n",
    "ranker = Ranker(val_path=val_path)\n",
    "ranked_response = ranker(parsed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([]), tensor([])),\n",
       " (tensor([ 2,  2,  2,  2, 16,  1,  1,  5,  5]),\n",
       "  tensor([[0.1333, 0.0312, 0.7333, 0.6562],\n",
       "          [0.1333, 0.0312, 0.7333, 0.6562],\n",
       "          [0.1333, 0.0312, 0.7333, 0.6562],\n",
       "          [0.1333, 0.0312, 0.7333, 0.6562],\n",
       "          [0.4333, 0.7375, 0.1333, 0.0125],\n",
       "          [0.0000, 0.0375, 1.0000, 0.0625],\n",
       "          [0.0000, 0.8625, 1.0000, 0.0625],\n",
       "          [0.2889, 0.8875, 0.4444, 0.0625],\n",
       "          [0.5333, 0.8875, 0.4444, 0.0625]])),\n",
       " (tensor([ 2,  2,  2,  2, 16,  1,  1,  5,  5]),\n",
       "  tensor([[0.0000, 0.0000, 0.3333, 0.2500],\n",
       "          [0.3333, 0.0000, 0.3333, 0.2500],\n",
       "          [0.6667, 0.0000, 0.3333, 0.2500],\n",
       "          [0.0000, 0.2500, 1.0000, 0.3750],\n",
       "          [0.0000, 0.6250, 1.0000, 0.0312],\n",
       "          [0.1111, 0.6875, 0.7778, 0.0312],\n",
       "          [0.1111, 0.7500, 0.7778, 0.0312],\n",
       "          [0.1111, 0.8125, 0.7778, 0.0938],\n",
       "          [0.1111, 0.9375, 0.7778, 0.0625]])),\n",
       " (tensor([]), tensor([])),\n",
       " (tensor([ 2,  2,  2,  2, 16,  1,  1,  5,  5]),\n",
       "  tensor([[0.0000, 0.0000, 1.0000, 1.0000],\n",
       "          [0.0333, 0.0188, 0.9333, 0.3125],\n",
       "          [0.0333, 0.3500, 0.9333, 0.3125],\n",
       "          [0.0333, 0.6812, 0.9333, 0.3125],\n",
       "          [0.4000, 0.8687, 0.2000, 0.0250],\n",
       "          [0.0333, 0.0188, 0.9333, 0.0188],\n",
       "          [0.0333, 0.3500, 0.9333, 0.0188],\n",
       "          [0.0333, 0.0188, 0.9333, 0.0750],\n",
       "          [0.0333, 0.3500, 0.9333, 0.0750]])),\n",
       " (tensor([]), tensor([])),\n",
       " (tensor([]), tensor([])),\n",
       " (tensor([]), tensor([])),\n",
       " (tensor([]), tensor([])),\n",
       " (tensor([ 2,  2,  2,  2, 16,  1,  1,  5,  5]),\n",
       "  tensor([[0.1556, 0.0375, 0.6889, 0.3750],\n",
       "          [0.1556, 0.4563, 0.6889, 0.3750],\n",
       "          [0.1556, 0.8750, 0.6889, 0.0875],\n",
       "          [0.8444, 0.8750, 0.1556, 0.0875],\n",
       "          [0.4000, 0.8500, 0.2000, 0.1125],\n",
       "          [0.0000, 0.0000, 1.0000, 0.0312],\n",
       "          [0.0000, 0.4437, 1.0000, 0.0312],\n",
       "          [0.1111, 0.6438, 0.7778, 0.1250],\n",
       "          [0.1111, 0.8188, 0.7778, 0.1250]]))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranked_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvisualization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Visualizer, create_image_grid\n\u001b[0;32m      4\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m Visualizer(dataset)\n\u001b[1;32m----> 5\u001b[0m images \u001b[38;5;241m=\u001b[39m visualizer(\u001b[43mranked_response\u001b[49m)\n\u001b[0;32m      6\u001b[0m create_image_grid(images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ranked_response' is not defined"
     ]
    }
   ],
   "source": [
    "from visualization import Visualizer, create_image_grid\n",
    "\n",
    "\n",
    "visualizer = Visualizer(dataset)\n",
    "images = visualizer(ranked_response)\n",
    "create_image_grid(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layoutprompter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
